{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNtraining.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Pygyz9hAsV1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYA_jV7RELsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io.wavfile as wav\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s9FsLGSoEMo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "allLabels = ['Barood','Blast', 'Bum', 'Fire','Khoon', \n",
        "             'Maar', 'Moat', 'Murder', 'Smuggle', 'Taawaan', 'negative']\n",
        "def get_labels(allLabels):\n",
        "    labels = allLabels\n",
        "    label_indices = np.arange(0, len(labels))\n",
        "    return labels, label_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IwhsJAQdENFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def wav2mfcc(file_path, max_len=100):\n",
        "    sr, wave = wav.read(file_path)\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=sr)\n",
        "\n",
        "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
        "    if (max_len > mfcc.shape[1]):\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    # Else cutoff the remaining parts\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "    \n",
        "    return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ac2eaf68-0f42-4c66-e345-7f79d3cc14a9",
        "id": "QYtXYRi3FmSF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "def get_train_test(split_ratio=0.8, random_state=42):\n",
        "    # Get available labels\n",
        "    labels, indices= get_labels(allLabels)\n",
        "\n",
        "    # Getting first arrays\n",
        "    X = np.load(labels[0] + '.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "    print(X.shape)\n",
        "\n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        print(label,i+1)\n",
        "        x = np.load(label + '.npy')\n",
        "        print(x.shape)\n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "\n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "  \n",
        "# Loading train set and test set\n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "print(X_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(979, 20, 100)\n",
            "Blast 1\n",
            "(998, 20, 100)\n",
            "Bum 2\n",
            "(1000, 20, 100)\n",
            "Fire 3\n",
            "(1000, 20, 100)\n",
            "Khoon 4\n",
            "(1000, 20, 100)\n",
            "Maar 5\n",
            "(1000, 20, 100)\n",
            "Moat 6\n",
            "(1000, 20, 100)\n",
            "Murder 7\n",
            "(999, 20, 100)\n",
            "Smuggle 8\n",
            "(999, 20, 100)\n",
            "Taawaan 9\n",
            "(999, 20, 100)\n",
            "negative 10\n",
            "(10000, 20, 100)\n",
            "(15979, 20, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2d1u-K6FWdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature 1 dimension\n",
        "feature_dim_1 = 20\n",
        "# Second dimension of the feature is dim2\n",
        "feature_dim_2 = 100\n",
        "\n",
        "channel = 1\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "verbose = 1\n",
        "num_classes = 11\n",
        "\n",
        "# Reshaping to perform 2D convolution\n",
        "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
        "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXdkUI1UJWWr",
        "colab_type": "code",
        "outputId": "320b656e-a3ac-499c-d6bc-b453b835d52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "CP = keras.callbacks.ModelCheckpoint('model-{epoch:03d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=1, \n",
        "                                     save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, callbacks = [CP], \n",
        "          validation_data=(X_test, y_test_hot))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15979 samples, validate on 3995 samples\n",
            "Epoch 1/20\n",
            "15979/15979 [==============================] - 14s 850us/step - loss: 2.5867 - acc: 0.5522 - val_loss: 0.8306 - val_acc: 0.7407\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.83062, saving model to model-001-0.83.h5\n",
            "Epoch 2/20\n",
            "15979/15979 [==============================] - 11s 686us/step - loss: 0.8442 - acc: 0.7355 - val_loss: 0.5256 - val_acc: 0.8463\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.83062 to 0.52557, saving model to model-002-0.53.h5\n",
            "Epoch 3/20\n",
            "15979/15979 [==============================] - 11s 679us/step - loss: 0.5574 - acc: 0.8256 - val_loss: 0.3529 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.52557 to 0.35294, saving model to model-003-0.35.h5\n",
            "Epoch 4/20\n",
            "15979/15979 [==============================] - 11s 682us/step - loss: 0.4067 - acc: 0.8706 - val_loss: 0.2954 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.35294 to 0.29544, saving model to model-004-0.30.h5\n",
            "Epoch 5/20\n",
            "15979/15979 [==============================] - 11s 678us/step - loss: 0.3087 - acc: 0.9011 - val_loss: 0.2472 - val_acc: 0.9259\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.29544 to 0.24715, saving model to model-005-0.25.h5\n",
            "Epoch 6/20\n",
            "15979/15979 [==============================] - 11s 681us/step - loss: 0.2316 - acc: 0.9233 - val_loss: 0.2569 - val_acc: 0.9229\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.24715\n",
            "Epoch 7/20\n",
            "15979/15979 [==============================] - 11s 675us/step - loss: 0.1943 - acc: 0.9369 - val_loss: 0.2471 - val_acc: 0.9334\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.24715 to 0.24707, saving model to model-007-0.25.h5\n",
            "Epoch 8/20\n",
            "15979/15979 [==============================] - 11s 679us/step - loss: 0.1582 - acc: 0.9475 - val_loss: 0.2452 - val_acc: 0.9372\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.24707 to 0.24522, saving model to model-008-0.25.h5\n",
            "Epoch 9/20\n",
            "15979/15979 [==============================] - 11s 676us/step - loss: 0.1319 - acc: 0.9560 - val_loss: 0.2135 - val_acc: 0.9352\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.24522 to 0.21354, saving model to model-009-0.21.h5\n",
            "Epoch 10/20\n",
            "15979/15979 [==============================] - 11s 683us/step - loss: 0.1223 - acc: 0.9577 - val_loss: 0.2364 - val_acc: 0.9354\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.21354\n",
            "Epoch 11/20\n",
            "15979/15979 [==============================] - 11s 674us/step - loss: 0.1093 - acc: 0.9627 - val_loss: 0.2284 - val_acc: 0.9367\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.21354\n",
            "Epoch 12/20\n",
            "15979/15979 [==============================] - 11s 675us/step - loss: 0.1019 - acc: 0.9647 - val_loss: 0.2522 - val_acc: 0.9419\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.21354\n",
            "Epoch 13/20\n",
            "15979/15979 [==============================] - 11s 675us/step - loss: 0.0928 - acc: 0.9687 - val_loss: 0.2100 - val_acc: 0.9397\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.21354 to 0.21002, saving model to model-013-0.21.h5\n",
            "Epoch 14/20\n",
            "15979/15979 [==============================] - 11s 676us/step - loss: 0.0851 - acc: 0.9718 - val_loss: 0.2144 - val_acc: 0.9382\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.21002\n",
            "Epoch 15/20\n",
            "15979/15979 [==============================] - 11s 679us/step - loss: 0.0773 - acc: 0.9720 - val_loss: 0.2519 - val_acc: 0.9397\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.21002\n",
            "Epoch 16/20\n",
            "15979/15979 [==============================] - 11s 676us/step - loss: 0.0727 - acc: 0.9746 - val_loss: 0.2017 - val_acc: 0.9439\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.21002 to 0.20175, saving model to model-016-0.20.h5\n",
            "Epoch 17/20\n",
            "15979/15979 [==============================] - 11s 676us/step - loss: 0.0672 - acc: 0.9752 - val_loss: 0.2423 - val_acc: 0.9417\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.20175\n",
            "Epoch 18/20\n",
            "15979/15979 [==============================] - 11s 676us/step - loss: 0.0632 - acc: 0.9767 - val_loss: 0.2610 - val_acc: 0.9419\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.20175\n",
            "Epoch 19/20\n",
            "15979/15979 [==============================] - 11s 673us/step - loss: 0.0625 - acc: 0.9776 - val_loss: 0.2286 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.20175\n",
            "Epoch 20/20\n",
            "15979/15979 [==============================] - 11s 674us/step - loss: 0.0656 - acc: 0.9776 - val_loss: 0.2603 - val_acc: 0.9467\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.20175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f855960a160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "w46CZvH2eTF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('model-016-0.20.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3gtDAuKSTAO",
        "colab_type": "code",
        "outputId": "38495e34-9eb1-40a4-b8b5-166258bdaefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Predicting one sample\n",
        "def predict(filepath, model):\n",
        "    sample = wav2mfcc(filepath)\n",
        "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
        "    print(model.predict(sample_reshaped))\n",
        "    return get_labels(allLabels)[0][\n",
        "            np.argmax(model.predict(sample_reshaped))\n",
        "    ]\n",
        "    \n",
        "\n",
        "model = model\n",
        "print(predict('5.wav', model=model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.7842256e-02 1.8564482e-04 8.9623392e-01 8.3583879e-04 4.0888963e-03\n",
            "  1.0611506e-03 1.0204834e-04 4.2228472e-05 4.8055600e-02 3.0836878e-02\n",
            "  7.1561296e-04]]\n",
            "1000Bum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hViuw9ZJsde9",
        "colab_type": "code",
        "outputId": "391b55aa-0766-4afd-e3c9-789df365c1f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 19, 99, 32)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 18, 98, 48)        6192      \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 17, 97, 120)       23160     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 8, 48, 120)        0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 8, 48, 120)        0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 46080)             0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 128)               5898368   \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 11)                715       \n",
            "=================================================================\n",
            "Total params: 5,936,851\n",
            "Trainable params: 5,936,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}